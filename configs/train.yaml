seed: 42

dataset:
  name: iamtarun/python_code_instructions_18k_alpaca
  split: train[:2000]
  # alt:
  # name: FinGPT/fingpt-sentiment-train
  # split: train[:2000]

model:
  base_id: unsloth/Meta-Llama-3.1-8B-bnb-4bit
  max_seq_len: 2048
  lora:
    r: 16
    alpha: 16
    dropout: 0
    target_modules: [q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj]

train:
  batch_size: 2
  grad_accum: 4
  epochs: 1
  lr: 2e-4
  log_steps: 10
  save_steps: 200
  out_dir: outputs/run1
